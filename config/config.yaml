# ==== Parameters ROS ==== #
TOPIC_CMD: 'cmd_vel'              # topic to publish the velocity
TOPIC_ODOM: 'odom'                # topic to get the odometry
TOPIC_SCAN: 'base_scan_front'     # topic to get the laser scan
ROBOT: 'robot'                    # name of the robot in gazebo

# ==== Parameters for the Environment ==== #
GOAL_REACHED_DIST: 1.0            # distance to the goal to consider it reached (in meters)
COLLISION_DIST: 0.3               # distance to the obstacle to consider it a collision (in meters)
ORIENTATION_THRESHOLD: 0.1        # threshold to consider the orientation reached (in radians)
ENVIRONMENT_DIM: 24              # size of the environment (default)
ROBOT_DIM: 4                      # distance, theta, velocity linear, velocity angular (default)
ACTION_DIM: 2                     # angular and linear (default)
TIME_DELTA: 1.0                   # 10 Hz (default)
NOISE_SIGMA: 0.1                  # noise for the laser scan (gaussian) 0.0 -> no noise 10.0 -> 100% noise
RANDOM_NEAR_OBSTACLE: true        # To take random actions near obstacles or not
MAX_RANGE: 20.0                   # max range of the laser scan

# ==== Path to the model and config ==== #
MODEL_PATH: '/home/user/ws/src/reinforcement/models/'         # default: 'models/'
CONFIG_PATH: '/home/user/ws/src/reinforcement/config/'        # default: 'config/'
RESULTS: '/home/user/ws/src/reinforcement/src/reinforcement/run/'    # default: 'results/'

TRAIN: '/home/user/ws/src/reinforcement/config/models/'

# ==== Path Weights pre-trained ==== #
MODEL: '/home/user/ws/src/reinforcement/src/reinforcement/checkpoints/' # default: 'checkpoints/'

# ==== Parameters Training ==== #
TYPE: 0                 # (0) -> Train from scratch, (1) -> Load model and continue training, (2) -> Test Model
BUFFER_SIZE: 1000000    # replay buffer size (default: 1e6)
BATCH_SIZE: 128         # minibatch size (default: 100)
TAU: 0.005              # for soft update of target parameters (default: 1e-3)
LR_ACTOR: 0.0001        # learning rate of the actor (default: 1e-3)
LR_CRITIC: 0.0001       # learning rate of the critic (default: 1e-3)
WEIGHT_DECAY: 0         # L2 weight decay (default: 0)

EPSILON: 1.0            # explore->exploit noise process added to act step (default: 1.0)
EPSILON_DECAY: 0.000005 # decay rate for noise process (default: 1e-5)

N_EPISODES: 200000      # maximum number of training episodes (default: 200000)
PRINT_EVERY: 10         # print results every n episodes (default: 1)
MAX_TIMESTEP: 100       # maximum number of timesteps per episode (default: 500)
SCORE_SOLVED: 1000000   # minimum score to be considered solved (default: 1000000.0)

POLICY_FREQ: 2          # frequency of delayed policy updates (default: 2)
POLICY_NOISE: 0.2       # std of Gaussian noise added to target policy during critic update (default: 0.2)
CLIP_PARAM: 0.5         # clipping parameter for TD3 policy updates (default: 0.5)
NOISE_CLIP: 0.5         # clipping range for TD3 noise (default: 0.5)
MAX_ACTION: 1           # maximum action magnitude (default: 1.0)
DISCOUNT: 0.99999       # discount factor (default: 0.9999)